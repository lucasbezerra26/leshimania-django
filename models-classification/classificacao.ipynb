{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affecting-network",
   "metadata": {},
   "source": [
    "# Classificação de imagens de leismaniose utilizando CNN pré-treinadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-somewhere",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alternate-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 28 23:09:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:09:00.0 Off |                  N/A |\n",
      "|  0%   49C    P0    77W / 300W |      1MiB / 11019MiB |     37%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:0A:00.0 Off |                  N/A |\n",
      "|  0%   39C    P8    11W / 300W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:42:00.0 Off |                  N/A |\n",
      "|  0%   39C    P8     2W / 300W |      1MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:43:00.0 Off |                  N/A |\n",
      "|  0%   38C    P8    18W / 300W |      1MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "furnished-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #aqui tem q escolher uma das gpus, veja a que esta desocupada (comando: nvidia-smi)\n",
    "tf_device='/gpu:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-boxing",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "missing-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "from keras.applications.densenet import DenseNet201\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import pickle # salvar modelo em disco\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fluid-output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Clésio Gonçalves\n",
      "\n",
      "pandas    : 1.2.3\n",
      "numpy     : 1.19.2\n",
      "matplotlib: 3.3.4\n",
      "tensorflow: 2.4.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Clésio Gonçalves\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-wright",
   "metadata": {},
   "source": [
    "## Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "choice-state",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dados de entrada\n",
    "PATH_IMAGES = 'dataset/'\n",
    "\n",
    "# Parâmetros do treinamento\n",
    "BATCH_SIZE = 10\n",
    "SEED = 42\n",
    "\n",
    "# K-fold\n",
    "N_SPLIT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "creative-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Remove o diretorio caso exista (antes de criá-lo)\n",
    "if os.path.exists(\"modelo\") and os.path.isdir(\"modelo\"):\n",
    "    shutil.rmtree(\"modelo\")\n",
    "    \n",
    "# Remove o diretorio caso exista (antes de criá-lo)\n",
    "if os.path.exists(\"resultados\") and os.path.isdir(\"resultados\"):\n",
    "    shutil.rmtree(\"resultados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vertical-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir modelo\n",
    "!mkdir resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "frequent-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros treinamento\n",
    "epocas_treinamento = 20\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "epocas_ajuste_fino = 10\n",
    "total_epocas = epocas_treinamento + epocas_ajuste_fino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-stuart",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "junior-killing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CATEGORIAS = ['Monkey Pox', 'Others']\n",
    "CATEGORIAS = ['Negativo', 'Positivo']\n",
    "NUM_CATEGORIAS = len(CATEGORIAS)\n",
    "NUM_CATEGORIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "western-chapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negativo 72 imagens\n",
      "Positivo 78 imagens\n"
     ]
    }
   ],
   "source": [
    "for category in CATEGORIAS:\n",
    "    print('{} {} imagens'.format(category, len(os.listdir(os.path.join(PATH_IMAGES, category)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "polar-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for category in CATEGORIAS:\n",
    "    for file in os.listdir(os.path.join(PATH_IMAGES, category)):\n",
    "        dataset.append(['{}/{}'.format(category, file), category])\n",
    "dataset = pd.DataFrame(dataset, columns=['arquivo', 'categoria'])\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "victorian-toilet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arquivo</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negativo/CM200826-124843056.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negativo/CM200826-122443024.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negativo/CM200826-122541026.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negativo/CM200826-144801011.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negativo/CM200826-144527006.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Positivo/CM200819-105910047.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Positivo/Imagem 13.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Positivo/CM200826-100032004.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Positivo/Imagem 34.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Positivo/Imagem 40.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             arquivo categoria\n",
       "0    Negativo/CM200826-124843056.jpg  Negativo\n",
       "1    Negativo/CM200826-122443024.jpg  Negativo\n",
       "2    Negativo/CM200826-122541026.jpg  Negativo\n",
       "3    Negativo/CM200826-144801011.jpg  Negativo\n",
       "4    Negativo/CM200826-144527006.jpg  Negativo\n",
       "..                               ...       ...\n",
       "145  Positivo/CM200819-105910047.jpg  Positivo\n",
       "146           Positivo/Imagem 13.jpg  Positivo\n",
       "147  Positivo/CM200826-100032004.jpg  Positivo\n",
       "148           Positivo/Imagem 34.jpg  Positivo\n",
       "149           Positivo/Imagem 40.jpg  Positivo\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "resistant-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo X e Y\n",
    "dataset_x = dataset.arquivo\n",
    "dataset_y = dataset.categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-dryer",
   "metadata": {},
   "source": [
    "# Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chronic-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Data Generators\n",
    "datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "three-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados de treino, validação e testes\n",
    "def leitura_dados(img_size):\n",
    "    train_dataset = datagen.flow_from_dataframe(dataframe = train_df, \n",
    "                                                      directory = PATH_IMAGES,\n",
    "                                                      x_col = \"arquivo\", \n",
    "                                                      y_col = \"categoria\",\n",
    "                                                      class_mode=\"binary\",\n",
    "                                                      target_size = img_size, \n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      seed = SEED,\n",
    "                                                      shuffle = True)\n",
    "\n",
    "    val_dataset = datagen.flow_from_dataframe(dataframe = val_df, \n",
    "                                                      directory = PATH_IMAGES,\n",
    "                                                      x_col = \"arquivo\", \n",
    "                                                      y_col = \"categoria\",\n",
    "                                                      class_mode=\"binary\",\n",
    "                                                      target_size = img_size, \n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      shuffle = False)\n",
    "\n",
    "    test_dataset = datagen.flow_from_dataframe(dataframe = test_df, \n",
    "                                                      directory = PATH_IMAGES,\n",
    "                                                      x_col = \"arquivo\", \n",
    "                                                      y_col = \"categoria\",\n",
    "                                                      class_mode=\"binary\",\n",
    "                                                      target_size = img_size, \n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      shuffle = False)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-calcium",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "olive-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria data frame de resultados\n",
    "colunas_dataframe = ['model', 'tp', 'fp', 'tn', 'fn', 'accuracy', 'kappa', 'precision', 'f1score', 'recall', 'specificity', 'roc_auc']\n",
    "resultados = pd.DataFrame(columns = colunas_dataframe)\n",
    "\n",
    "def calcula_metricas_binarias(y_true, y_pred):\n",
    "    \n",
    "    global resultados\n",
    "    \n",
    "    # Cutoff\n",
    "    y_true = (y_true > 0.5).flatten()\n",
    "    y_pred = (y_pred > 0.5).flatten()\n",
    "\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1score = f1_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    specificity = (1.0 * tn) / (tn + fp)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    metricas = {'model': models[rede].name, \n",
    "                'tp': tp, \n",
    "                'fp': fp,\n",
    "                'tn': tn,\n",
    "                'fn': fn,\n",
    "                'accuracy': accuracy,\n",
    "                'kappa': kappa,\n",
    "                'precision': precision,\n",
    "                'f1score': f1score,\n",
    "                'recall': recall,\n",
    "                'specificity': specificity,\n",
    "                'roc_auc':roc_auc}\n",
    "    \n",
    "    print(metricas)\n",
    "    \n",
    "    resultados = resultados.append(metricas, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-evanescence",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "straight-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura dos pesos pré-treinados da ImageNet\n",
    "# Não inclui as camadas de classificação no topo, ideal para extração de features\n",
    "models = [\n",
    "    DenseNet201(weights = \"imagenet\", input_shape = (224, 224, 3), include_top = False),\n",
    "    InceptionV3(weights='imagenet', input_shape=(299, 299, 3), include_top=False),\n",
    "    Xception(weights='imagenet', input_shape=(299, 299, 3), include_top=False),\n",
    "    InceptionResNetV2(weights='imagenet', input_shape=(299, 299, 3), include_top=False),\n",
    "    NASNetLarge(weights='imagenet', input_shape=(331, 331, 3), include_top=False),\n",
    "    ResNet152V2(weights='imagenet', input_shape=(224, 224, 3), include_top=False)\n",
    "]\n",
    "\n",
    "# Reescala dos valores dos pixels do modelo\n",
    "processamento_input = [\n",
    "    keras.applications.densenet.preprocess_input,\n",
    "    keras.applications.inception_v3.preprocess_input,\n",
    "    keras.applications.xception.preprocess_input,\n",
    "    keras.applications.inception_resnet_v2.preprocess_input,\n",
    "    keras.applications.nasnet.preprocess_input,\n",
    "    keras.applications.resnet_v2.preprocess_input\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "systematic-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir um modelo a partir de redes neurais pré-treinadas\n",
    "def modelo_base(rede):\n",
    "    \n",
    "    base_model = models[rede]\n",
    "    img_size = (base_model.input.shape[1], base_model.input.shape[2])\n",
    "    \n",
    "    # Processa as entradas do modelo\n",
    "    preprocess_input = processamento_input[rede]\n",
    "    \n",
    "    return base_model, img_size, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cutting-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando aumento de dados aleatórios somente no fit (treinamento)\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        #keras.layers.experimental.preprocessing.RandomRotation(0.9), \n",
    "        keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "        keras.layers.experimental.preprocessing.RandomContrast(0.2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "diagnostic-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir modelo\n",
    "def build_model():\n",
    "    \n",
    "    # Freeze the base_model\n",
    "    # Congela a base convolucional antes de compilar e treinar o modelo\n",
    "    # Evita que os pesos em uma determinada camada sejam atualizados durante o treinamento\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Arquitetura do modelo básico\n",
    "    # base_model.summary()\n",
    "\n",
    "    # Adiciona o cabeçalho de classificação\n",
    "    # Converter as features do shape `base_model.output_shape[1:] para vectores\n",
    "    global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "    # Aplica uma camada densa para converter essas features em uma única previsão por imagem\n",
    "    # Os números > 0.5 preveem a classe 1, os números <= 0.5 preveem a classe 0\n",
    "    prediction_layer = keras.layers.Dense(1, activation=\"sigmoid\", name='predictions') # Função de ativação sigmoid adicionada\n",
    "\n",
    "    # Modelo encadeando as camadas de aumento de dados, reescalonamento, base_model e extrator de features\n",
    "    img_shape = img_size + (3,)\n",
    "    inputs = keras.Input(shape = img_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acknowledged-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile o modelo antes de treiná-lo\n",
    "def compile_model(learning_rate):\n",
    "    \n",
    "    # Compilar modelo\n",
    "    # Não especifiquei o batch_size, pois os dados já estão em conjuntos (batchs)\n",
    "    model.compile(optimizer = Adam(lr = learning_rate), loss = keras.losses.BinaryCrossentropy(), metrics = ['binary_accuracy'])\n",
    "    \n",
    "    # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "thirty-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos um checkpoint para verificar regularmente se a perda em validação diminuiu\n",
    "# Se a performance melhorar em validação salvamos o modelo\n",
    "# Podemos ainda optar por salvar o modelo a cada número de épocas\n",
    "# callbacks\n",
    "# Redução gradual da taxa de aprendizado (Reduce on Plateau)\n",
    "def get_callbacks():\n",
    "    return [EarlyStopping(monitor = 'val_loss', patience = 10, verbose = 1),\n",
    "            ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, min_lr = 0.0000001, verbose = 1),\n",
    "            ModelCheckpoint('modelo/{}.h5'.format(models[rede].name), \n",
    "                         verbose = 1, \n",
    "                         save_best_only = True, \n",
    "                         save_weights_only = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "written-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo\n",
    "def salva_estrutura_modelo():\n",
    "    \n",
    "    # salva o modelo em disco\n",
    "    # pickle.dump(model, open(f'modelo/{models[rede].name}.pkl', 'wb'))\n",
    "    model.save(f'modelo/{models[rede].name}')\n",
    "    \n",
    "    # salva json\n",
    "    arquivo_modelo = f'modelo/{models[rede].name}.json'\n",
    "    modelo_json = model.to_json()\n",
    "    with open(arquivo_modelo, 'w') as json_file:\n",
    "        json_file.write(modelo_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "driven-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "def treinamento_model(qnt_epocas, epoca_inicial):\n",
    "    \n",
    "    history = model.fit(train_dataset,\n",
    "                        epochs = qnt_epocas,\n",
    "                        initial_epoch = epoca_inicial,\n",
    "                        validation_data = val_dataset,\n",
    "                        verbose=1,\n",
    "                        callbacks = get_callbacks())\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "addressed-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de aprendizado da precisão / perda de treinamento e validação ao usar o modelo\n",
    "def aprendizado_treinamento():\n",
    "    \n",
    "    metricas_graficos = [\"loss\", \"binary_accuracy\"]\n",
    "          \n",
    "    fig, ax = plt.subplots(len(metricas_graficos), 1, figsize=(10, len(metricas_graficos)*6))\n",
    "    ax = ax.ravel()\n",
    "    dados_x = np.arange(1, epocas_treinamento+1, 1)\n",
    "\n",
    "    for i, met in enumerate(metricas_graficos):        \n",
    "        ax[i].plot(dados_x, history.history[met], label='Training ' + met)\n",
    "        ax[i].plot(dados_x, history.history[\"val_\" + met], label='Validation ' + met)\n",
    "        ax[i].set_title(\"Training and Validation %s in model %s\" %(met, models[rede].name))\n",
    "        ax[i].set_xlabel(\"epochs\")\n",
    "        ax[i].set_ylabel(met)\n",
    "        \n",
    "        if (i != 0): # loss function\n",
    "            ax[i].legend(loc='lower right')\n",
    "        else:\n",
    "            ax[i].legend(loc='upper right')\n",
    "    \n",
    "    return metricas_graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "relevant-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMIAR PARA AJUSTE FINO (OPCIONAL)\n",
    "# Definir as camadas inferiores como não treináveis\n",
    "def limiar_ajuste_fino():\n",
    "    \n",
    "    # Exibe a quantidade de camadas do modelo base\n",
    "    # print(\"Número de camadas no modelo base: \", len(base_model.layers))\n",
    "\n",
    "    # Ajuste fino desta camada em diante\n",
    "    fine_tune_at = 100\n",
    "\n",
    "    # Congele todas as camadas antes da camada 'fine_tune_at'\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "several-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste fino\n",
    "def ajuste_fino():\n",
    "    \n",
    "    # Foi treinado apenas algumas camadas do modelo. \n",
    "    # Os pesos da rede pré-treinada não foram atualizados durante o treinamento.\n",
    "    # Uma maneira de aumentar ainda mais o desempenho é treinar (ou \"ajustar\") os pesos das camadas superiores \n",
    "    # do modelo pré-treinado junto com o treinamento do classificador adicionado (camada de classificação adicionada)\n",
    "    # Descongelar as camadas superiores do modelo (descongelar base_model)\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Limiar ajuste fino (OPCIONAL)\n",
    "    limiar_ajuste_fino()\n",
    "    \n",
    "    # É necessário recompilar o modelo (para que essas alterações tenham efeito)\n",
    "    # É importante usar uma taxa de aprendizado mais baixa neste estágio, \n",
    "    # pois está usando um modelo muito maior e deseja readaptar os pesos pré-treinados\n",
    "    compile_model(base_learning_rate/10)\n",
    "    \n",
    "    # Retomar o treinamento melhorará sua precisão em alguns pontos percentuais\n",
    "    # history.epoch[-1] é a última época do ultimo treinamento\n",
    "    history_fine = treinamento_model(total_epocas, history.epoch[-1]+1)\n",
    "    \n",
    "    return history_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baking-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de aprendizado da precisão / perda de treinamento e validação ao ajustar as últimas camadas do modelo\n",
    "def aprendizado_ajuste_fino():\n",
    "    \n",
    "    fig, ax = plt.subplots(len(metricas_graficos), 1, figsize=(12, len(metricas_graficos)*6))\n",
    "    ax = ax.ravel()\n",
    "    dados_x = np.arange(1, len(history.history['loss']) + len(history_fine.history['loss'])+1, 1)\n",
    "\n",
    "    for i, met in enumerate(metricas_graficos):\n",
    "        dados_treino = history.history[met] + history_fine.history[met]\n",
    "        dados_validacao = history.history[\"val_\" + met] + history_fine.history[\"val_\" + met]\n",
    "        \n",
    "        ax[i].plot(dados_x, dados_treino, label='Training ' + met)\n",
    "        ax[i].plot(dados_x, dados_validacao, label='Validation ' + met)\n",
    "        ax[i].plot([epocas_treinamento, epocas_treinamento], plt.ylim(), label='Start Fine Tuning')\n",
    "        ax[i].set_title(\"Training and Validation %s in model %s\" %(met, models[rede].name))\n",
    "        ax[i].set_xlabel(\"epochs\")\n",
    "        ax[i].set_ylabel(met)\n",
    "        \n",
    "        if (i != 0): # loss function\n",
    "            ax[i].legend(loc='lower right')\n",
    "        else:\n",
    "            ax[i].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-period",
   "metadata": {},
   "source": [
    "# Treinamento K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "unusual-committee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================\n",
      "Iteração 1 de 5\n",
      "======================================================\n",
      "\n",
      "Executando modelo densenet201\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 13s 542ms/step - loss: 0.9885 - binary_accuracy: 0.4028 - val_loss: 1.0203 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.02028, saving model to modelo/densenet201.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.8643 - binary_accuracy: 0.4142 - val_loss: 0.9272 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.02028 to 0.92718, saving model to modelo/densenet201.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.8278 - binary_accuracy: 0.4250 - val_loss: 0.8749 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.92718 to 0.87492, saving model to modelo/densenet201.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.7832 - binary_accuracy: 0.4998 - val_loss: 0.8277 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87492 to 0.82765, saving model to modelo/densenet201.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 0.8490 - binary_accuracy: 0.3591 - val_loss: 0.7950 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.82765 to 0.79498, saving model to modelo/densenet201.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.7912 - binary_accuracy: 0.4707 - val_loss: 0.7675 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.79498 to 0.76755, saving model to modelo/densenet201.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.8039 - binary_accuracy: 0.4352 - val_loss: 0.7513 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.76755 to 0.75133, saving model to modelo/densenet201.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.8402 - binary_accuracy: 0.3388 - val_loss: 0.7348 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.75133 to 0.73478, saving model to modelo/densenet201.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.7408 - binary_accuracy: 0.4982 - val_loss: 0.7413 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.73478\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 0.7085 - binary_accuracy: 0.5790 - val_loss: 0.7302 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.73478 to 0.73017, saving model to modelo/densenet201.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.7465 - binary_accuracy: 0.5367 - val_loss: 0.7071 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.73017 to 0.70712, saving model to modelo/densenet201.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.7081 - binary_accuracy: 0.5445 - val_loss: 0.6857 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.70712 to 0.68572, saving model to modelo/densenet201.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.6874 - binary_accuracy: 0.5518 - val_loss: 0.6667 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68572 to 0.66666, saving model to modelo/densenet201.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.7054 - binary_accuracy: 0.5593 - val_loss: 0.6649 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.66666 to 0.66490, saving model to modelo/densenet201.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.6963 - binary_accuracy: 0.5128 - val_loss: 0.6663 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.66490\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.7401 - binary_accuracy: 0.4842 - val_loss: 0.6541 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.66490 to 0.65409, saving model to modelo/densenet201.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.6516 - binary_accuracy: 0.5734 - val_loss: 0.6396 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.65409 to 0.63964, saving model to modelo/densenet201.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.6696 - binary_accuracy: 0.6069 - val_loss: 0.6166 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.63964 to 0.61661, saving model to modelo/densenet201.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.6251 - binary_accuracy: 0.6337 - val_loss: 0.6037 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.61661 to 0.60375, saving model to modelo/densenet201.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.6524 - binary_accuracy: 0.6345 - val_loss: 0.5982 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.60375 to 0.59822, saving model to modelo/densenet201.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 17s 494ms/step - loss: 0.5396 - binary_accuracy: 0.7111 - val_loss: 0.2781 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.27814, saving model to modelo/densenet201.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.3578 - binary_accuracy: 0.8222 - val_loss: 0.1310 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.27814 to 0.13104, saving model to modelo/densenet201.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.2450 - binary_accuracy: 0.9156 - val_loss: 0.0483 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.13104 to 0.04831, saving model to modelo/densenet201.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.1467 - binary_accuracy: 0.9556 - val_loss: 0.0266 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.04831 to 0.02655, saving model to modelo/densenet201.h5\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 298ms/step - loss: 0.1749 - binary_accuracy: 0.9464 - val_loss: 0.0158 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.02655 to 0.01584, saving model to modelo/densenet201.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.1221 - binary_accuracy: 0.9670 - val_loss: 0.0108 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01584 to 0.01075, saving model to modelo/densenet201.h5\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.0489 - binary_accuracy: 0.9954 - val_loss: 0.0090 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01075 to 0.00904, saving model to modelo/densenet201.h5\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.0360 - binary_accuracy: 1.0000 - val_loss: 0.0088 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00904 to 0.00884, saving model to modelo/densenet201.h5\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 0.0619 - binary_accuracy: 0.9823 - val_loss: 0.0029 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00884 to 0.00293, saving model to modelo/densenet201.h5\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 0.0240 - binary_accuracy: 0.9941 - val_loss: 0.0034 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00293\n",
      "INFO:tensorflow:Assets written to: modelo/densenet201/assets\n",
      "3/3 [==============================] - 4s 335ms/step\n",
      "{'model': 'densenet201', 'tp': 14, 'fp': 0, 'tn': 14, 'fn': 2, 'accuracy': 0.9333333333333333, 'kappa': 0.8672566371681416, 'precision': 1.0, 'f1score': 0.9333333333333333, 'recall': 0.875, 'specificity': 1.0, 'roc_auc': 0.9375}\n",
      "\n",
      "Executando modelo inception_v3\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 7s 385ms/step - loss: 0.7100 - binary_accuracy: 0.5061 - val_loss: 0.7136 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71359, saving model to modelo/inception_v3.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.6677 - binary_accuracy: 0.5775 - val_loss: 0.6759 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.71359 to 0.67593, saving model to modelo/inception_v3.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.6447 - binary_accuracy: 0.6360 - val_loss: 0.6519 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67593 to 0.65193, saving model to modelo/inception_v3.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.5919 - binary_accuracy: 0.6907 - val_loss: 0.6407 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.65193 to 0.64071, saving model to modelo/inception_v3.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.6167 - binary_accuracy: 0.6440 - val_loss: 0.6239 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.64071 to 0.62392, saving model to modelo/inception_v3.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.6427 - binary_accuracy: 0.5675 - val_loss: 0.6006 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62392 to 0.60060, saving model to modelo/inception_v3.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.6458 - binary_accuracy: 0.7216 - val_loss: 0.5823 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60060 to 0.58233, saving model to modelo/inception_v3.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.5766 - binary_accuracy: 0.7279 - val_loss: 0.5872 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.58233\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.5468 - binary_accuracy: 0.7127 - val_loss: 0.5681 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.58233 to 0.56812, saving model to modelo/inception_v3.h5\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.5886 - binary_accuracy: 0.5921 - val_loss: 0.5592 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56812 to 0.55920, saving model to modelo/inception_v3.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 0.5541 - binary_accuracy: 0.7518 - val_loss: 0.5394 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.55920 to 0.53943, saving model to modelo/inception_v3.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.5625 - binary_accuracy: 0.7560 - val_loss: 0.5222 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.53943 to 0.52222, saving model to modelo/inception_v3.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 0.5171 - binary_accuracy: 0.7665 - val_loss: 0.5112 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.52222 to 0.51121, saving model to modelo/inception_v3.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 274ms/step - loss: 0.5554 - binary_accuracy: 0.7367 - val_loss: 0.5066 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.51121 to 0.50658, saving model to modelo/inception_v3.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.5503 - binary_accuracy: 0.7416 - val_loss: 0.4913 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.50658 to 0.49130, saving model to modelo/inception_v3.h5\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.5708 - binary_accuracy: 0.7318 - val_loss: 0.4936 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.49130\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 0.5125 - binary_accuracy: 0.7667 - val_loss: 0.4832 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.49130 to 0.48316, saving model to modelo/inception_v3.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.4732 - binary_accuracy: 0.8202 - val_loss: 0.4705 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.48316 to 0.47055, saving model to modelo/inception_v3.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.5029 - binary_accuracy: 0.8064 - val_loss: 0.4593 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.47055 to 0.45928, saving model to modelo/inception_v3.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.4729 - binary_accuracy: 0.8078 - val_loss: 0.4525 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.45928 to 0.45253, saving model to modelo/inception_v3.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 11s 354ms/step - loss: 0.5152 - binary_accuracy: 0.7285 - val_loss: 0.2690 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.26897, saving model to modelo/inception_v3.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.3463 - binary_accuracy: 0.8569 - val_loss: 0.2488 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.26897 to 0.24885, saving model to modelo/inception_v3.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.3111 - binary_accuracy: 0.8809 - val_loss: 0.0876 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.24885 to 0.08758, saving model to modelo/inception_v3.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.2575 - binary_accuracy: 0.9201 - val_loss: 0.1462 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08758\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 270ms/step - loss: 0.1863 - binary_accuracy: 0.9462 - val_loss: 0.0353 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.08758 to 0.03535, saving model to modelo/inception_v3.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.1018 - binary_accuracy: 0.9635 - val_loss: 0.0733 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03535\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.1421 - binary_accuracy: 0.9118 - val_loss: 0.0232 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.03535 to 0.02319, saving model to modelo/inception_v3.h5\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.0372 - binary_accuracy: 0.9984 - val_loss: 0.0142 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.02319 to 0.01418, saving model to modelo/inception_v3.h5\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.0501 - binary_accuracy: 1.0000 - val_loss: 0.0099 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01418 to 0.00993, saving model to modelo/inception_v3.h5\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.0342 - binary_accuracy: 0.9906 - val_loss: 0.0218 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00993\n",
      "INFO:tensorflow:Assets written to: modelo/inception_v3/assets\n",
      "3/3 [==============================] - 2s 345ms/step\n",
      "{'model': 'inception_v3', 'tp': 15, 'fp': 0, 'tn': 14, 'fn': 1, 'accuracy': 0.9666666666666667, 'kappa': 0.9333333333333333, 'precision': 1.0, 'f1score': 0.967741935483871, 'recall': 0.9375, 'specificity': 1.0, 'roc_auc': 0.96875}\n",
      "\n",
      "Executando modelo xception\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 8s 344ms/step - loss: 0.6565 - binary_accuracy: 0.5730 - val_loss: 0.6869 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68691, saving model to modelo/xception.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 246ms/step - loss: 0.6534 - binary_accuracy: 0.6560 - val_loss: 0.6706 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68691 to 0.67064, saving model to modelo/xception.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.6694 - binary_accuracy: 0.5499 - val_loss: 0.6560 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67064 to 0.65596, saving model to modelo/xception.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.6548 - binary_accuracy: 0.6472 - val_loss: 0.6436 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.65596 to 0.64360, saving model to modelo/xception.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.6355 - binary_accuracy: 0.6722 - val_loss: 0.6312 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.64360 to 0.63116, saving model to modelo/xception.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.6125 - binary_accuracy: 0.7178 - val_loss: 0.6204 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.63116 to 0.62044, saving model to modelo/xception.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.5930 - binary_accuracy: 0.8401 - val_loss: 0.6127 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62044 to 0.61272, saving model to modelo/xception.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.5864 - binary_accuracy: 0.7417 - val_loss: 0.6063 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.61272 to 0.60634, saving model to modelo/xception.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 234ms/step - loss: 0.5691 - binary_accuracy: 0.7964 - val_loss: 0.6038 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.60634 to 0.60377, saving model to modelo/xception.h5\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.5632 - binary_accuracy: 0.7934 - val_loss: 0.5987 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.60377 to 0.59865, saving model to modelo/xception.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.5850 - binary_accuracy: 0.7672 - val_loss: 0.5872 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.59865 to 0.58720, saving model to modelo/xception.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 0.5959 - binary_accuracy: 0.6521 - val_loss: 0.5788 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.58720 to 0.57879, saving model to modelo/xception.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 0.5700 - binary_accuracy: 0.8202 - val_loss: 0.5725 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.57879 to 0.57254, saving model to modelo/xception.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.5822 - binary_accuracy: 0.7526 - val_loss: 0.5682 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.57254 to 0.56823, saving model to modelo/xception.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.5527 - binary_accuracy: 0.8050 - val_loss: 0.5657 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.56823 to 0.56569, saving model to modelo/xception.h5\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.5441 - binary_accuracy: 0.7821 - val_loss: 0.5617 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.56569 to 0.56172, saving model to modelo/xception.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.5620 - binary_accuracy: 0.7343 - val_loss: 0.5551 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.56172 to 0.55515, saving model to modelo/xception.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.5633 - binary_accuracy: 0.8101 - val_loss: 0.5482 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.55515 to 0.54817, saving model to modelo/xception.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.5279 - binary_accuracy: 0.8215 - val_loss: 0.5450 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.54817 to 0.54496, saving model to modelo/xception.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 0.5474 - binary_accuracy: 0.7760 - val_loss: 0.5395 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.54496 to 0.53946, saving model to modelo/xception.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 6s 336ms/step - loss: 0.5032 - binary_accuracy: 0.8037 - val_loss: 0.4883 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.48829, saving model to modelo/xception.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.4856 - binary_accuracy: 0.8642 - val_loss: 0.4346 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.48829 to 0.43463, saving model to modelo/xception.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.4204 - binary_accuracy: 0.8839 - val_loss: 0.3605 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.43463 to 0.36045, saving model to modelo/xception.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.3736 - binary_accuracy: 0.8553 - val_loss: 0.3135 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.36045 to 0.31352, saving model to modelo/xception.h5\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.3865 - binary_accuracy: 0.8260 - val_loss: 0.2763 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.31352 to 0.27629, saving model to modelo/xception.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.2881 - binary_accuracy: 0.9479 - val_loss: 0.2437 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.27629 to 0.24374, saving model to modelo/xception.h5\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.2914 - binary_accuracy: 0.8816 - val_loss: 0.2324 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.24374 to 0.23239, saving model to modelo/xception.h5\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 0.2499 - binary_accuracy: 0.9095 - val_loss: 0.1942 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.23239 to 0.19425, saving model to modelo/xception.h5\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.2452 - binary_accuracy: 0.9142 - val_loss: 0.1750 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19425 to 0.17501, saving model to modelo/xception.h5\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.2361 - binary_accuracy: 0.9267 - val_loss: 0.1428 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.17501 to 0.14276, saving model to modelo/xception.h5\n",
      "INFO:tensorflow:Assets written to: modelo/xception/assets\n",
      "3/3 [==============================] - 1s 346ms/step\n",
      "{'model': 'xception', 'tp': 14, 'fp': 0, 'tn': 14, 'fn': 2, 'accuracy': 0.9333333333333333, 'kappa': 0.8672566371681416, 'precision': 1.0, 'f1score': 0.9333333333333333, 'recall': 0.875, 'specificity': 1.0, 'roc_auc': 0.9375}\n",
      "\n",
      "Executando modelo inception_resnet_v2\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 14s 543ms/step - loss: 0.8176 - binary_accuracy: 0.3861 - val_loss: 0.7731 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.77307, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 0.7422 - binary_accuracy: 0.5063 - val_loss: 0.7758 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.77307\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.7143 - binary_accuracy: 0.4915 - val_loss: 0.7765 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.77307\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 0.7235 - binary_accuracy: 0.5255 - val_loss: 0.7763 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.77307\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.7103 - binary_accuracy: 0.4871 - val_loss: 0.7580 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.77307 to 0.75804, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.7098 - binary_accuracy: 0.4482 - val_loss: 0.7456 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.75804 to 0.74557, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.7050 - binary_accuracy: 0.5351 - val_loss: 0.7295 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.74557 to 0.72949, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.6509 - binary_accuracy: 0.6074 - val_loss: 0.7167 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.72949 to 0.71670, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.6403 - binary_accuracy: 0.6489 - val_loss: 0.7124 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.71670 to 0.71237, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.6574 - binary_accuracy: 0.6920 - val_loss: 0.7048 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.71237 to 0.70476, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.6341 - binary_accuracy: 0.6092 - val_loss: 0.6940 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.70476 to 0.69401, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 0.6580 - binary_accuracy: 0.5851 - val_loss: 0.6809 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.69401 to 0.68091, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.6686 - binary_accuracy: 0.5321 - val_loss: 0.6597 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68091 to 0.65974, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.6204 - binary_accuracy: 0.6253 - val_loss: 0.6592 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.65974 to 0.65917, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 272ms/step - loss: 0.6084 - binary_accuracy: 0.7070 - val_loss: 0.6571 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.65917 to 0.65709, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.6153 - binary_accuracy: 0.6815 - val_loss: 0.6474 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.65709 to 0.64739, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 0.6190 - binary_accuracy: 0.6521 - val_loss: 0.6374 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.64739 to 0.63743, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.5641 - binary_accuracy: 0.8120 - val_loss: 0.6225 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.63743 to 0.62246, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.6364 - binary_accuracy: 0.5777 - val_loss: 0.6234 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.62246\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.6044 - binary_accuracy: 0.7289 - val_loss: 0.6241 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.62246\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 17s 529ms/step - loss: 0.5747 - binary_accuracy: 0.7566 - val_loss: 0.4091 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.40911, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.4804 - binary_accuracy: 0.7733 - val_loss: 0.2988 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.40911 to 0.29885, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.3409 - binary_accuracy: 0.7872 - val_loss: 0.1218 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.29885 to 0.12177, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.1909 - binary_accuracy: 0.9429 - val_loss: 0.2463 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.12177\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 281ms/step - loss: 0.1336 - binary_accuracy: 0.9396 - val_loss: 0.0266 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.12177 to 0.02664, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.1394 - binary_accuracy: 0.9108 - val_loss: 0.0906 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.02664\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 277ms/step - loss: 0.1352 - binary_accuracy: 0.9531 - val_loss: 0.0190 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.02664 to 0.01896, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 0.0591 - binary_accuracy: 0.9925 - val_loss: 0.0144 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01896 to 0.01443, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 0.0183 - binary_accuracy: 1.0000 - val_loss: 0.0142 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.01443 to 0.01423, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.0200 - binary_accuracy: 1.0000 - val_loss: 0.0049 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01423 to 0.00486, saving model to modelo/inception_resnet_v2.h5\n",
      "INFO:tensorflow:Assets written to: modelo/inception_resnet_v2/assets\n",
      "3/3 [==============================] - 5s 363ms/step\n",
      "{'model': 'inception_resnet_v2', 'tp': 16, 'fp': 0, 'tn': 14, 'fn': 0, 'accuracy': 1.0, 'kappa': 1.0, 'precision': 1.0, 'f1score': 1.0, 'recall': 1.0, 'specificity': 1.0, 'roc_auc': 1.0}\n",
      "\n",
      "Executando modelo NASNet\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 18s 678ms/step - loss: 0.7289 - binary_accuracy: 0.5194 - val_loss: 0.6703 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.67027, saving model to modelo/NASNet.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 277ms/step - loss: 0.7372 - binary_accuracy: 0.4455 - val_loss: 0.6616 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.67027 to 0.66165, saving model to modelo/NASNet.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.6737 - binary_accuracy: 0.5443 - val_loss: 0.6516 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.66165 to 0.65159, saving model to modelo/NASNet.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.6567 - binary_accuracy: 0.6325 - val_loss: 0.6378 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.65159 to 0.63778, saving model to modelo/NASNet.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.6814 - binary_accuracy: 0.6218 - val_loss: 0.6241 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.63778 to 0.62407, saving model to modelo/NASNet.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.6662 - binary_accuracy: 0.6260 - val_loss: 0.6049 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62407 to 0.60494, saving model to modelo/NASNet.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 246ms/step - loss: 0.6354 - binary_accuracy: 0.7135 - val_loss: 0.5942 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60494 to 0.59418, saving model to modelo/NASNet.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.6209 - binary_accuracy: 0.7010 - val_loss: 0.5762 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.59418 to 0.57619, saving model to modelo/NASNet.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 0.6164 - binary_accuracy: 0.7702 - val_loss: 0.5661 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.57619 to 0.56607, saving model to modelo/NASNet.h5\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 0.6079 - binary_accuracy: 0.8026 - val_loss: 0.5529 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56607 to 0.55293, saving model to modelo/NASNet.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 273ms/step - loss: 0.5916 - binary_accuracy: 0.7282 - val_loss: 0.5344 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.55293 to 0.53444, saving model to modelo/NASNet.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.5588 - binary_accuracy: 0.8680 - val_loss: 0.5196 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.53444 to 0.51960, saving model to modelo/NASNet.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.5387 - binary_accuracy: 0.8887 - val_loss: 0.5050 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.51960 to 0.50498, saving model to modelo/NASNet.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.5566 - binary_accuracy: 0.7784 - val_loss: 0.4988 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.50498 to 0.49877, saving model to modelo/NASNet.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.5500 - binary_accuracy: 0.8622 - val_loss: 0.4895 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.49877 to 0.48954, saving model to modelo/NASNet.h5\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.5544 - binary_accuracy: 0.7967 - val_loss: 0.4811 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.48954 to 0.48114, saving model to modelo/NASNet.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.5273 - binary_accuracy: 0.7749 - val_loss: 0.4662 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.48114 to 0.46616, saving model to modelo/NASNet.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.5154 - binary_accuracy: 0.8941 - val_loss: 0.4555 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.46616 to 0.45547, saving model to modelo/NASNet.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.5235 - binary_accuracy: 0.7787 - val_loss: 0.4477 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.45547 to 0.44768, saving model to modelo/NASNet.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.4933 - binary_accuracy: 0.8399 - val_loss: 0.4460 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.44768 to 0.44598, saving model to modelo/NASNet.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 36s 1s/step - loss: 0.5203 - binary_accuracy: 0.7873 - val_loss: 0.2964 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.29636, saving model to modelo/NASNet.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 6s 524ms/step - loss: 0.3697 - binary_accuracy: 0.8385 - val_loss: 0.1633 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.29636 to 0.16329, saving model to modelo/NASNet.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 6s 526ms/step - loss: 0.1852 - binary_accuracy: 0.9712 - val_loss: 0.0683 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.16329 to 0.06830, saving model to modelo/NASNet.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 6s 541ms/step - loss: 0.1567 - binary_accuracy: 0.9509 - val_loss: 0.0319 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.06830 to 0.03185, saving model to modelo/NASNet.h5\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 6s 526ms/step - loss: 0.0666 - binary_accuracy: 0.9925 - val_loss: 0.0153 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.03185 to 0.01528, saving model to modelo/NASNet.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 6s 533ms/step - loss: 0.0444 - binary_accuracy: 1.0000 - val_loss: 0.0071 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01528 to 0.00706, saving model to modelo/NASNet.h5\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 6s 533ms/step - loss: 0.0166 - binary_accuracy: 0.9954 - val_loss: 0.0122 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00706\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 6s 540ms/step - loss: 0.0621 - binary_accuracy: 0.9984 - val_loss: 0.0103 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00706\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 6s 531ms/step - loss: 0.1240 - binary_accuracy: 0.9479 - val_loss: 0.0137 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00706\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 6s 562ms/step - loss: 0.0098 - binary_accuracy: 0.9984 - val_loss: 0.0026 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00706 to 0.00264, saving model to modelo/NASNet.h5\n",
      "INFO:tensorflow:Assets written to: modelo/NASNet/assets\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1ca4f0c700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 7s 353ms/step\n",
      "{'model': 'NASNet', 'tp': 16, 'fp': 0, 'tn': 14, 'fn': 0, 'accuracy': 1.0, 'kappa': 1.0, 'precision': 1.0, 'f1score': 1.0, 'recall': 1.0, 'specificity': 1.0, 'roc_auc': 1.0}\n",
      "\n",
      "Executando modelo resnet152v2\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 17s 1s/step - loss: 1.1731 - binary_accuracy: 0.4489 - val_loss: 1.5537 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.55367, saving model to modelo/resnet152v2.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.9994 - binary_accuracy: 0.4772 - val_loss: 1.3946 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.55367 to 1.39459, saving model to modelo/resnet152v2.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.8633 - binary_accuracy: 0.5508 - val_loss: 1.2640 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.39459 to 1.26396, saving model to modelo/resnet152v2.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 0.8737 - binary_accuracy: 0.4824 - val_loss: 1.1602 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.26396 to 1.16023, saving model to modelo/resnet152v2.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.8267 - binary_accuracy: 0.4961 - val_loss: 1.0781 - val_binary_accuracy: 0.2500\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16023 to 1.07813, saving model to modelo/resnet152v2.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.7746 - binary_accuracy: 0.5460 - val_loss: 1.0189 - val_binary_accuracy: 0.2500\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.07813 to 1.01887, saving model to modelo/resnet152v2.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 0.8355 - binary_accuracy: 0.4482 - val_loss: 0.9788 - val_binary_accuracy: 0.2500\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.01887 to 0.97879, saving model to modelo/resnet152v2.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.7826 - binary_accuracy: 0.5190 - val_loss: 0.9472 - val_binary_accuracy: 0.1875\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.97879 to 0.94718, saving model to modelo/resnet152v2.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 0.8028 - binary_accuracy: 0.5045 - val_loss: 0.9107 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.94718 to 0.91073, saving model to modelo/resnet152v2.h5\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 246ms/step - loss: 0.8270 - binary_accuracy: 0.4558 - val_loss: 0.8911 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.91073 to 0.89107, saving model to modelo/resnet152v2.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.6347 - binary_accuracy: 0.5881 - val_loss: 0.8704 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.89107 to 0.87036, saving model to modelo/resnet152v2.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 0.7084 - binary_accuracy: 0.5671 - val_loss: 0.8597 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.87036 to 0.85969, saving model to modelo/resnet152v2.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 0.7406 - binary_accuracy: 0.5281 - val_loss: 0.8440 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.85969 to 0.84396, saving model to modelo/resnet152v2.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.6243 - binary_accuracy: 0.6740 - val_loss: 0.8326 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.84396 to 0.83259, saving model to modelo/resnet152v2.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.7142 - binary_accuracy: 0.5397 - val_loss: 0.8188 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.83259 to 0.81881, saving model to modelo/resnet152v2.h5\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.6971 - binary_accuracy: 0.5875 - val_loss: 0.7977 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.81881 to 0.79766, saving model to modelo/resnet152v2.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.6427 - binary_accuracy: 0.6580 - val_loss: 0.7711 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.79766 to 0.77109, saving model to modelo/resnet152v2.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.6426 - binary_accuracy: 0.6288 - val_loss: 0.7410 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.77109 to 0.74095, saving model to modelo/resnet152v2.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 0.6092 - binary_accuracy: 0.7229 - val_loss: 0.7327 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.74095 to 0.73271, saving model to modelo/resnet152v2.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.6156 - binary_accuracy: 0.6443 - val_loss: 0.7275 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.73271 to 0.72753, saving model to modelo/resnet152v2.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 16s 465ms/step - loss: 0.6470 - binary_accuracy: 0.6561 - val_loss: 0.5354 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.53537, saving model to modelo/resnet152v2.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 0.4556 - binary_accuracy: 0.7816 - val_loss: 0.2236 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.53537 to 0.22362, saving model to modelo/resnet152v2.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 246ms/step - loss: 0.2641 - binary_accuracy: 0.9058 - val_loss: 0.1156 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.22362 to 0.11555, saving model to modelo/resnet152v2.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 0.1791 - binary_accuracy: 0.9587 - val_loss: 0.0475 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.11555 to 0.04749, saving model to modelo/resnet152v2.h5\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.1012 - binary_accuracy: 0.9427 - val_loss: 0.0182 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.04749 to 0.01819, saving model to modelo/resnet152v2.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.1123 - binary_accuracy: 0.9329 - val_loss: 0.0339 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01819\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.0361 - binary_accuracy: 0.9965 - val_loss: 0.0268 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01819\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.0427 - binary_accuracy: 1.0000 - val_loss: 0.0286 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01819\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.0279 - binary_accuracy: 1.0000 - val_loss: 0.0195 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01819\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.0233 - binary_accuracy: 1.0000 - val_loss: 0.0307 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01819\n",
      "INFO:tensorflow:Assets written to: modelo/resnet152v2/assets\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1ca6ed6280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 4s 344ms/step\n",
      "{'model': 'resnet152v2', 'tp': 14, 'fp': 0, 'tn': 14, 'fn': 2, 'accuracy': 0.9333333333333333, 'kappa': 0.8672566371681416, 'precision': 1.0, 'f1score': 0.9333333333333333, 'recall': 0.875, 'specificity': 1.0, 'roc_auc': 0.9375}\n",
      "CPU times: user 19min 34s, sys: 50.1 s, total: 20min 24s\n",
      "Wall time: 21min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# k-fold\n",
    "kfold = StratifiedKFold(n_splits = N_SPLIT, shuffle = True, random_state = SEED)\n",
    "\n",
    "# Contador de iterações do k-fold\n",
    "iteracao = 1\n",
    "\n",
    "train_idx, test_idx = list(kfold.split(dataset_x, dataset_y))[3] # só execuro o código no 4º fold\n",
    "    \n",
    "print(\"\\n======================================================\")\n",
    "print(\"Iteração {} de {}\".format(iteracao, N_SPLIT))\n",
    "print(\"======================================================\")\n",
    "\n",
    "trein_temp = dataset.iloc[train_idx]\n",
    "test_df = dataset.iloc[test_idx] # 20% teste\n",
    "\n",
    "# dividir o teste em validação e teste\n",
    "train_df, val_df = train_test_split(trein_temp, test_size = 0.13, random_state = SEED) # 10% validação e 70% treino\n",
    "\n",
    "for rede in range(len(models)): # Todos os modelos\n",
    "\n",
    "    print('\\nExecutando modelo {}'.format(models[rede].name))\n",
    "\n",
    "    # Modelo base\n",
    "    base_model, img_size, preprocess_input = modelo_base(rede)\n",
    "\n",
    "    # Leitura dos dados\n",
    "    train_dataset, val_dataset, test_dataset = leitura_dados(img_size)\n",
    "\n",
    "    # Construir modelo\n",
    "    model = build_model()\n",
    "\n",
    "    # Compilar Modelo\n",
    "    compile_model(base_learning_rate)\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    history = treinamento_model(epocas_treinamento, 0)\n",
    "\n",
    "    # Curvas de aprendizado da precisão / perda de treinamento e validação ao usar o modelo\n",
    "    # metricas_graficos = aprendizado_treinamento()\n",
    "\n",
    "    # Ajuste fino\n",
    "    history_fine = ajuste_fino()\n",
    "\n",
    "    # Curvas de aprendizado da precisão / perda de treinamento e validação ao ajustar as últimas camadas do modelo\n",
    "    # aprendizado_ajuste_fino()\n",
    "\n",
    "    # Carrega o melhor modelo\n",
    "    model.load_weights('modelo/{}.h5'.format(models[rede].name))\n",
    "\n",
    "    # Salva a estrutura do modelo\n",
    "    salva_estrutura_modelo()\n",
    "\n",
    "    # Obtemos os rótulos verdadeiros\n",
    "    y_true = np.array(test_dataset.classes)\n",
    "\n",
    "    # Obtemos os rótulos previstos\n",
    "    y_pred = model.predict(test_dataset, verbose = 1)\n",
    "    # y_pred = previsoes.argmax(axis=1)\n",
    "\n",
    "    # Calcula métricas Binárias\n",
    "    calcula_metricas_binarias(y_true, y_pred)\n",
    "\n",
    "    # Limpa a sessão\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "iteracao = iteracao + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sunrise-therapy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>kappa</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1score</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>densenet201</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xception</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inception_resnet_v2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NASNet</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet152v2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.867257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.93750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  tp fp  tn fn  accuracy     kappa  precision   f1score  \\\n",
       "0          densenet201  14  0  14  2  0.933333  0.867257        1.0  0.933333   \n",
       "1         inception_v3  15  0  14  1  0.966667  0.933333        1.0  0.967742   \n",
       "2             xception  14  0  14  2  0.933333  0.867257        1.0  0.933333   \n",
       "3  inception_resnet_v2  16  0  14  0  1.000000  1.000000        1.0  1.000000   \n",
       "4               NASNet  16  0  14  0  1.000000  1.000000        1.0  1.000000   \n",
       "5          resnet152v2  14  0  14  2  0.933333  0.867257        1.0  0.933333   \n",
       "\n",
       "   recall  specificity  roc_auc  \n",
       "0  0.8750          1.0  0.93750  \n",
       "1  0.9375          1.0  0.96875  \n",
       "2  0.8750          1.0  0.93750  \n",
       "3  1.0000          1.0  1.00000  \n",
       "4  1.0000          1.0  1.00000  \n",
       "5  0.8750          1.0  0.93750  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "municipal-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados de todas as iterações\n",
    "resultados.to_csv('resultados/resultados.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
